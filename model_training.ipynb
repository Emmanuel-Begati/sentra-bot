{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52df852",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Crop Image Classification Pipeline\n",
    "\n",
    "This script implements a complete pipeline for training, validating and testing\n",
    "image classification models on crop disease datasets.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Import Libraries =====\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm  # For progress bars\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"training.log\"), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "# scikit-learn for evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# For visualization\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0609c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "# ===== Section: Configuration Settings =====\n",
    "# Configuration class to hold all settings\n",
    "class Config:\n",
    "    # Paths\n",
    "    data_dir = \"./dataset\"\n",
    "    output_dir = \"./models\"\n",
    "    results_dir = \"./results\"\n",
    "\n",
    "    # Dataset settings\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    test_ratio = 0.15\n",
    "\n",
    "    # Model settings\n",
    "    model_type = \"resnet50\"  # Options: 'custom_cnn', 'resnet18', 'resnet50'\n",
    "    pretrained = True\n",
    "\n",
    "    # Training settings\n",
    "    batch_size = 32\n",
    "    num_epochs = 30\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    # Early stopping settings\n",
    "    patience = 5\n",
    "\n",
    "    # Image settings\n",
    "    img_size = 224\n",
    "\n",
    "    # Device settings\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(Config.output_dir, exist_ok=True)\n",
    "os.makedirs(Config.results_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Data Preparation =====\n",
    "def get_data_transforms():\n",
    "    \"\"\"Define data transformations for training and validation/testing.\"\"\"\n",
    "    # Data augmentation and normalization for training\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(Config.img_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(p=0.2),\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Just normalization for validation & testing\n",
    "    val_test_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(Config.img_size + 32),\n",
    "            transforms.CenterCrop(Config.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return train_transform, val_test_transform\n",
    "\n",
    "\n",
    "def load_and_split_dataset():\n",
    "    \"\"\"Load the dataset and split it into train, validation and test sets.\"\"\"\n",
    "    train_transform, val_test_transform = get_data_transforms()\n",
    "\n",
    "    # Load the full dataset with training transformations\n",
    "    full_dataset = datasets.ImageFolder(root=Config.data_dir, transform=train_transform)\n",
    "\n",
    "    # Create a dataset with validation/test transformations\n",
    "    val_test_dataset = datasets.ImageFolder(\n",
    "        root=Config.data_dir, transform=val_test_transform\n",
    "    )\n",
    "\n",
    "    # Get class names and count\n",
    "    class_names = full_dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    print(f\"Found {num_classes} classes: {class_names}\")\n",
    "\n",
    "    # Calculate splits\n",
    "    dataset_size = len(full_dataset)\n",
    "    train_size = int(Config.train_ratio * dataset_size)\n",
    "    val_size = int(Config.val_ratio * dataset_size)\n",
    "    test_size = dataset_size - train_size - val_size\n",
    "\n",
    "    print(f\"Total dataset size: {dataset_size}\")\n",
    "    print(f\"Training set size: {train_size}\")\n",
    "    print(f\"Validation set size: {val_size}\")\n",
    "    print(f\"Testing set size: {test_size}\")\n",
    "\n",
    "    # Create the splits\n",
    "    train_dataset, val_dataset_with_aug, test_dataset_with_aug = random_split(\n",
    "        full_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "\n",
    "    # Create validation and test datasets with proper transforms\n",
    "    # We want to keep the same data points but use different transforms\n",
    "    _, val_dataset_proper, test_dataset_proper = random_split(\n",
    "        val_test_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42),\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train_dataset,\n",
    "        val_dataset_proper,\n",
    "        test_dataset_proper,\n",
    "        class_names,\n",
    "        num_classes,\n",
    "    )\n",
    "\n",
    "\n",
    "def create_dataloaders(train_dataset, val_dataset, test_dataset):\n",
    "    \"\"\"Create DataLoader objects for train, validation, and test datasets.\"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Model Architectures =====\n",
    "class CustomCNN(nn.Module):\n",
    "    \"\"\"Custom CNN architecture for baseline comparison.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "def get_model(model_type, num_classes, pretrained=True):\n",
    "    \"\"\"Create a model based on the specified type.\"\"\"\n",
    "    print(f\"Creating {model_type} model...\")\n",
    "\n",
    "    if model_type == \"custom_cnn\":\n",
    "        model = CustomCNN(num_classes)\n",
    "\n",
    "    elif model_type == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=pretrained)\n",
    "        # Replace the final fully connected layer\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    elif model_type == \"resnet50\":\n",
    "        model = models.resnet50(pretrained=pretrained)\n",
    "        # Replace the final fully connected layer\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Model type {model_type} not supported\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ae733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Training Functions =====\n",
    "def train_model(\n",
    "    model, dataloaders, criterion, optimizer, scheduler=None, num_epochs=25\n",
    "):\n",
    "    \"\"\"Train the model with validation and early stopping.\"\"\"\n",
    "    since = time.time()\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    # For tracking metrics\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
    "\n",
    "    device = Config.device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model has {total_params:,} parameters, {trainable_params:,} are trainable\")\n",
    "\n",
    "    # Early stopping setup\n",
    "    patience = Config.patience\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass - track gradients only in training phase\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward pass + optimize only in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Calculate metrics for this epoch\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # Store history\n",
    "            if phase == \"train\":\n",
    "                history[\"train_loss\"].append(epoch_loss)\n",
    "                history[\"train_acc\"].append(epoch_acc.item())\n",
    "                if scheduler:\n",
    "                    scheduler.step()\n",
    "            else:\n",
    "                history[\"val_loss\"].append(epoch_loss)\n",
    "                history[\"val_acc\"].append(epoch_acc.item())\n",
    "\n",
    "            print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # If we got a better validation accuracy, save the model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict().copy()\n",
    "                best_epoch = epoch\n",
    "                early_stop_counter = 0\n",
    "\n",
    "                # Save the best model\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"accuracy\": best_acc,\n",
    "                    },\n",
    "                    os.path.join(Config.output_dir, f\"{Config.model_type}_best.pth\"),\n",
    "                )\n",
    "\n",
    "            elif phase == \"val\":\n",
    "                early_stop_counter += 1\n",
    "\n",
    "        # Check for early stopping\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
    "            break\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:.4f} at epoch {best_epoch + 1}\")\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774c7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Evaluation Functions =====\n",
    "def evaluate_model(model, test_loader, class_names):\n",
    "    \"\"\"Evaluate the model on the test set and return metrics.\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(Config.device)\n",
    "\n",
    "    # Lists to store predictions and true labels\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # No gradient calculation needed for evaluation\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(Config.device)\n",
    "            labels = labels.to(Config.device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(\n",
    "        all_labels, all_preds, target_names=class_names, digits=3\n",
    "    )\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return accuracy, conf_matrix, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Visualization Functions =====\n",
    "def plot_training_history(history, save_path=None):\n",
    "    \"\"\"Plot training and validation loss/accuracy curves.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[\"train_loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot training & validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[\"train_acc\"], label=\"Training Accuracy\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        print(f\"Training history plot saved to {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names, save_path=None):\n",
    "    \"\"\"Plot the confusion matrix as a heatmap.\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # Normalize the confusion matrix\n",
    "    norm_conf_matrix = (\n",
    "        conf_matrix.astype(\"float\") / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "        norm_conf_matrix,\n",
    "        annot=True,\n",
    "        cmap=\"Blues\",\n",
    "        fmt=\".2f\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.yticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e586f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Prediction Demo =====\n",
    "def predict_random_images(model, test_dataset, class_names, num_images=5):\n",
    "    \"\"\"Display and predict random images from the test set.\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(Config.device)\n",
    "\n",
    "    # Get a batch of random indices\n",
    "    indices = torch.randperm(len(test_dataset))[:num_images]\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(15, 3 * num_images))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get image and label\n",
    "        image, label = test_dataset[idx]\n",
    "\n",
    "        # Convert image for display\n",
    "        image_for_display = image.clone()\n",
    "\n",
    "        # Make prediction\n",
    "        image = image.unsqueeze(0).to(Config.device)\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "        # Get predicted and true class names\n",
    "        predicted_class = class_names[predicted.item()]\n",
    "        true_class = class_names[label]\n",
    "\n",
    "        # Display the image\n",
    "        plt.subplot(num_images, 1, i + 1)\n",
    "        plt.imshow(np.transpose(image_for_display.cpu().numpy(), (1, 2, 0)))\n",
    "\n",
    "        # Normalize the image for better display\n",
    "        plt.title(f\"True: {true_class} | Predicted: {predicted_class}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Color based on correctness\n",
    "        if predicted.item() == label:\n",
    "            plt.title(\n",
    "                f\"True: {true_class} | Predicted: {predicted_class}\", color=\"green\"\n",
    "            )\n",
    "        else:\n",
    "            plt.title(f\"True: {true_class} | Predicted: {predicted_class}\", color=\"red\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(Config.results_dir, \"sample_predictions.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d14364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Section: Main Execution =====\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    # 1. Load and prepare data\n",
    "    print(\"Preparing datasets...\")\n",
    "    train_dataset, val_dataset, test_dataset, class_names, num_classes = (\n",
    "        load_and_split_dataset()\n",
    "    )\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        train_dataset, val_dataset, test_dataset\n",
    "    )\n",
    "    dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "    # 2. Create model\n",
    "    model = get_model(Config.model_type, num_classes, Config.pretrained)\n",
    "    model = model.to(Config.device)\n",
    "\n",
    "    # 3. Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Different learning rates for different parts of the model if using transfer learning\n",
    "    if Config.model_type != \"custom_cnn\" and Config.pretrained:\n",
    "        # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        params_to_update = []\n",
    "        params_to_fine_tune = []\n",
    "\n",
    "        # Split parameters into those to update and those to fine-tune\n",
    "        for name, param in model.named_parameters():\n",
    "            if \"fc\" in name:  # Parameters in the final classifier layer\n",
    "                params_to_update.append(param)\n",
    "            else:\n",
    "                params_to_fine_tune.append(param)\n",
    "\n",
    "        # Optimizer with different learning rates\n",
    "        optimizer = optim.Adam(\n",
    "            [\n",
    "                {\"params\": params_to_fine_tune, \"lr\": Config.learning_rate / 10},\n",
    "                {\"params\": params_to_update},\n",
    "            ],\n",
    "            lr=Config.learning_rate,\n",
    "            weight_decay=Config.weight_decay,\n",
    "        )\n",
    "    else:\n",
    "        # Use the same learning rate for all parameters in custom CNN\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=Config.learning_rate,\n",
    "            weight_decay=Config.weight_decay,\n",
    "        )\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "    # 4. Train the model\n",
    "    print(f\"\\nTraining {Config.model_type} model on {Config.device}...\")\n",
    "    model, history = train_model(\n",
    "        model, dataloaders, criterion, optimizer, scheduler, Config.num_epochs\n",
    "    )\n",
    "\n",
    "    # 5. Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    accuracy, conf_matrix, report = evaluate_model(model, test_loader, class_names)\n",
    "\n",
    "    # 6. Visualize results\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "\n",
    "    # Plot training history\n",
    "    plot_training_history(\n",
    "        history,\n",
    "        save_path=os.path.join(\n",
    "            Config.results_dir, f\"{Config.model_type}_training_history.png\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix,\n",
    "        class_names,\n",
    "        save_path=os.path.join(\n",
    "            Config.results_dir, f\"{Config.model_type}_confusion_matrix.png\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # 7. Demo predictions on random images\n",
    "    print(\"\\nGenerating sample predictions...\")\n",
    "    predict_random_images(model, test_dataset, class_names, num_images=5)\n",
    "\n",
    "    # 8. Save final model\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        os.path.join(Config.output_dir, f\"{Config.model_type}_final.pth\"),\n",
    "    )\n",
    "    print(\n",
    "        f\"Final model saved to {os.path.join(Config.output_dir, f'{Config.model_type}_final.pth')}\"\n",
    "    )\n",
    "\n",
    "    # 9. Save model configuration and results\n",
    "    report_str = report.replace(\"\\n\", \"<br>\")\n",
    "    with open(os.path.join(Config.results_dir, \"model_report.md\"), \"w\") as f:\n",
    "        f.write(f\"# Model Training Report\\n\\n\")\n",
    "        f.write(f\"## Configuration\\n\\n\")\n",
    "        f.write(f\"- Model: {Config.model_type}\\n\")\n",
    "        f.write(f\"- Pretrained: {Config.pretrained}\\n\")\n",
    "        f.write(f\"- Image size: {Config.img_size}x{Config.img_size}\\n\")\n",
    "        f.write(f\"- Batch size: {Config.batch_size}\\n\")\n",
    "        f.write(f\"- Learning rate: {Config.learning_rate}\\n\")\n",
    "        f.write(f\"- Weight decay: {Config.weight_decay}\\n\\n\")\n",
    "        f.write(f\"## Results\\n\\n\")\n",
    "        f.write(f\"- Best test accuracy: {accuracy:.4f}\\n\\n\")\n",
    "        f.write(f\"## Classification Report\\n\\n\")\n",
    "        f.write(f\"```\\n{report}\\n```\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"Model report saved to {os.path.join(Config.results_dir, 'model_report.md')}\"\n",
    "    )\n",
    "\n",
    "    # 10. Save training history as JSON for future reference\n",
    "    history_dict = {\n",
    "        \"train_loss\": [float(val) for val in history[\"train_loss\"]],\n",
    "        \"val_loss\": [float(val) for val in history[\"val_loss\"]],\n",
    "        \"train_acc\": [float(val) for val in history[\"train_acc\"]],\n",
    "        \"val_acc\": [float(val) for val in history[\"val_acc\"]],\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(Config.results_dir, \"training_history.json\"), \"w\") as f:\n",
    "        json.dump(history_dict, f, indent=4)\n",
    "\n",
    "    print(\n",
    "        f\"Training history saved to {os.path.join(Config.results_dir, 'training_history.json')}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6e420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64508473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
